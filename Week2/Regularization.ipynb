{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization nedir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bugüne kadar hep en düşük \"loss\" değerine ulaşmaya çalıştık ki modelimiz bir şeyler öğrendiğini bize kanıtlasın ama şöyle bir durum var ki modelimiz ezberlemeye başlamış da olabilir. işte bunun önüne geçmek için **_regularization_** kullanıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization makine öğrenmesi alanında mutlaka bilinmesi ve çok iyi öğrenilmesi gereken bir yöntemdir. Bildiğiniz üzere makine öğrenmesinde başta gelen sorunlardan birisi **overfitting** yani modelimizin eğitim setimizi ezberlemesi durumu. Neredeyse 0 olan loss değerini gördüğümüzde sevinip bir de test ettiğimizde üzülmemize neden olan bu durumu **regularization** ile nasıl çözebiliriz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overfitting**i nasıl anlarız?  Elimizde **train** ve **validation** setlerimiz var. Bunları bir eğitim sürecine sokalım. Loss değeri beklenildiği üzere zamanla azalacak, her iki veri seti için. Fakat bazen öyle bir an gelecek ki **train** setimiz **0** a yaklaşırken **validation** setimizin loss değeri artmaya başlayacak. İşte bu durumda modelimiz ona verdiğimiz eğitim verilerini ezberlemeye başlamış ve artık test ettiğimiz validation verileri üzerinde yanlış tahminler yapmaya başlamış demektir. Buna **overfitting** diyoruz.\n",
    "\n",
    "![overfitting](images/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization da iki yöntem var. L1 (Lasso regression) , L2 (Ridge regression). Biz burada L2 regularization dan bahsediyor olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization ( Ridge Regression )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization'da, normal linear regression problemlerinde kullanmış olduğumuz loss fonksiyonuna ek olarak, olağandışı ağırlık değerlerini cezalandırabileceğimiz\n",
    "bir matematiksel işlem ekleyeceğiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimizde **loss** ve **regularization** için  iki fonksiyonumuz olacak. \n",
    "\n",
    "Bunlar **Loss** ve **complexity**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reg1](images/reg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eklemiş olduğumuz yeni fonksiyonda ağırlıklarımızın karelerini alıyor olacağız. Ayrıca **Lambda** dediğimiz ve bizim veri setlerimize göre değişkenlik gösterecek bir parametremiz daha var. Böylelikle formülümüz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reg2](images/reg2.png) olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lambda** seçimi ise kritik rol oynamaktadır. Şöyle ki: \n",
    "- lamda 0 seçilirse regularization fonksiyonumu işlev dışı kalır ve bir işe yaramaz yani **overfitting** ihtimali vardır.\n",
    "- lambda çok büyük seçilirse ağırlıkları cezalandırmada problem yaşar ve **underfitting** durumu söz konusu olur. \n",
    "\n",
    "Yukarıda da bahsettiğim üzere **lambda** seçimi veri setine ve içerisindeki özelliklere göre değişiklik gösterecektir ama genellikle **0 - 1** arası değerler kullanılmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Enes Çavuş_**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
