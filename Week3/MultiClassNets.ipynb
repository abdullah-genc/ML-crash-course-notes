{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi - Class Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"One vs All\"  vs \"Softmax\"\n",
    "\n",
    "Şu ana kadar sadece bir output üzerinde çalıştık.\n",
    "\n",
    "Peki daha fazla output varsa ?\n",
    "\n",
    "Örneğin: Kedi , Köpek , Elma , Muz , Kitap ...\n",
    "\n",
    "Modele bir fotoğraf verelim ve yukarıdakilerden hangisine ait oldugunu bulsun?. Yüzeysel olarak incelenen bu konuda sadece output üzerinde anlatım yapılmış. İnceleyelim...\n",
    "\n",
    "**One vs All** baskınlığa dayalı bir yöntem. Resmimiz tahmin edilirken, köpek ağır basıyorsa diğer olasılıkları direkt eleyerek \"bu köpek\" diyecektir.  \n",
    "\n",
    "\n",
    "![OnevsAll](images/OnevsAll.png)\n",
    "\n",
    "\n",
    "**Softmax** ise outputlarımız üzerinde tahmin yaparken **_olasılıklar_** döndürür. Yani **One vs All** normal linear regression ise **Softmax** logistic regression gibi düşünebilirsiniz. ( Sadece ouput farklarının anlaşılması için verdiğim bir örnek, yoksa tabii ki farklar var.)\n",
    "\n",
    "\n",
    "![Softmax](images/Softmax.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Clas Nets [Colab Egzersizi](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/multi-class_classification_with_MNIST.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=multiclass_tf2-colab&hl=en)\n",
    "\n",
    "\n",
    "Not: Sadece önemli olduğunu düşündüğüm kodları ekliyorum. Dğier kısımlar önceki egzersizlerle aynı.\n",
    "\n",
    "\n",
    "\n",
    "Bu kodda farklı olarak\n",
    "\n",
    " - Keras kütüphanesinden \"Flatten\" fonksiyonu var. Bu fonksiyon resmimizin iki boyutlu (28 x 28 ) lik matrisi tek boyutlu ( 784 ) matris  haline geritiyor ve verimizi modele aktarmamız çok daha kolaylaşıyor aynı zamanda modelin veriyi işlemesi de hızlanmış oluyor.\n",
    "\n",
    "\n",
    "- Aktivasyon olarak yine \"ReLU\" kullanıldıgını görüyoruz.\n",
    "\n",
    "- Farklı olarak \"Dropout\" fonskiyonu var. Nedir bu Dropout?\n",
    "\n",
    "Droput layer bir regularization işlemidir. L2 L1 da yaptığımız gibi, düğümlerimizin üzerinde ağırlıkları kontrol eder, anlamsız ve işe yaramayanların üzerinde işlem yapar. Overfitting probleminden kaçınmamızı sağlar. Daha fazlası için kaynak sondaki ektedir.\n",
    "\n",
    "- Son olarak ise \"Softmax\" output katmanımız. Görüldüğü üzere 10 farklı unit var demişiz çünkü veri setimiz MNIST yani 0 - 9 arasındaki değerler. \"Softmax\",  tıpkı ReLU gibi activation olarak belirtiliyor. \n",
    "\n",
    "\n",
    "Sonraki eğitim aşamaları diğer örneklerimizde olduğu gibi devam etmektedir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "  \n",
    "  # All models in this course are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a a one-dimensional \n",
    "  # 784-element array.\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  \n",
    "  # Define a dropout regularization layer. \n",
    "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "  # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "                           \n",
    "  # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ek kaynaklar\n",
    "- [One vs All](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/one-vs-all)\n",
    "- [Softmax](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax)\n",
    "-[Dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Enes Çavuş_**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
