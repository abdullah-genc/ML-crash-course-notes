{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train And Test Sets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimizin loss değeri ne kadar az ise o kadar iyi diyebiliriz fakat şöyle bir durum var modelimiz veri setimizi ezberlemiş olabiliri! Buna **overfitting** diyoruz. Yani modelimiz eğitim aşamasında çok güzel tahminlerde bulunuyor fakat modelimize daha önce görmediği, eğitim setinde bulunmayan bir veri verdiğimizde bize yanlış tahminlerde bulunuyor ise overfitting durumuna gelmiştir diyoruz. \n",
    "\n",
    "Bunun önüne geçebilmek için verimizi iki parçaya bölüyoruz \n",
    "\n",
    "- **Train** data . ( modelimiz kendini bu verileri kullanarak eğitecek )\n",
    "- **Test**  data : ( tahminlerini kontrol etmek için test seti üzerinde de denemeler yapacak ) \n",
    "\n",
    "![trainandtest](images/trainandtest.png)\n",
    "\n",
    "Verimizin ne kadarını test ne kadarını train olarak kullanacağız?\n",
    "\n",
    "Bu konuda çeşitli öneriler olsa da yeni başlayanlar için projelerinde %20 test civarında  pratik yapmaları iyi olacaktır. Daha sonra tecrübeleriniz arttıkça ve veri setlerinizi tanıdıkça kendiniz bu değerleri belirleyebileceksiniz. Örneğin ben bir görüntü işleme projesinde %15 test %85 train oranında güzel tahminler elde etmiştim. Ama her konuda olduğu gibi bu da **data dependent** yani verinize göre değişir. Kullandığım fotoğrafların kaliteleri değiştiğinde yüzdeler üzerinde oynamam gerektiği de oldu.\n",
    "\n",
    "\n",
    "\n",
    "Bu örneklerden sonra bir diğer problem olan **test setimiz üzerindeki overfitting'e** deyineceğiz. Bu nasıl oluyor?\n",
    "\n",
    "Modeliniz train set üzerinde ezberleme yapabildiği gibi aynı zamanda test set üzerinde de ezberleme yapabilir? Tahminlerini test setinde kontrol ederken bu kez ağırlıklarını test setine göre ayarlamaya başlayabilir. Bunu çözmek için ne yapıyoruz. Veri setimizi ikiye değil üçe bölüyoruz. Üçüncüsü ise **Validation Set**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farkı anlamamız için aşağıdaki resimleri inceleyelim. \n",
    "\n",
    "![valitest](images/valitest.png)\n",
    "\n",
    "Görüldüğü üzere modelimizi train - test setleri ile eğittiğimizde en iyi modeli seçiyoruz ve gerçek dünyaya alıyoruz. Test seti üzerinde bir overfitting söz konusu mu değil mi bilmiyoruz. \n",
    "\n",
    "Birde şu resimlere bakalım. \n",
    "\n",
    "Bu kez üçe böldük ve verimizin büyük bir kısmını train seti, bir kısmını validation set, bir kısmını test set olarak ayırdık.\n",
    "\n",
    "Modelimizin şimdi yapacağı iş train seti üzerinde denemeler yapacak ve validation üzerinde doğrulamalar yapacak. \n",
    "\n",
    "![valitest2](images/valitest2.png)\n",
    "\n",
    "![valitest3](images/valitest3.png)\n",
    "\n",
    "Bir önceki konuda olduğu gibi ama bir fark var: test seti değil validation seti üzerinde denemeler yapıyor. \n",
    "\n",
    "Eğitim tamamlandıktan sonra modelimizi gerçek dünyaya alıyoruz ve ayırmış olduğumuz test seti üzerinde denemelerde bulunuyoruz. \n",
    "\n",
    "Burada, modelimiz validation test üzerinde overfitting yapmış mı yoksa yapmamış mı anlayabiliyoruz. Yani overfitting'den bir basamak daha uzaklaşmış olduk. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ek olarak train - test mantığının daha iyi anlaşılabileceğini düşündüğüm  cross validation konusunu da buraya kaynak olarak eklemek istiyorum. Araştırılabilir ...\n",
    "\n",
    "- [Cross Validation](https://www.youtube.com/watch?v=fSytzGwwBVw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ek Kaynaklar:\n",
    "\n",
    "- [Google Original Link - Train & Test](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data)\n",
    "- [Google Original Link - Validation ](https://developers.google.com/machine-learning/crash-course/validation/another-partition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Enes Çavuş_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
